{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader as DataLoader\n",
    "from torchvision import transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the raw MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( (0.1307, ), (0.3081, ))])\n",
    "\n",
    "train_set = datasets.MNIST(root = \"data/\", train = True, transform = transform, download = True)\n",
    "test_set = datasets.MNIST(root = \"data/\", train = False, transform = transform, download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasplits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_size = int(train_size*len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_set, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(dataset = test_set, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample visualization of a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    9     9     7     5\n"
     ]
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join(f'{labels[j]:5}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 10, out_channels = 20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2)\n",
    "        self.fc1 = nn.Linear(in_features = 320, out_features = 50)\n",
    "        self.fc2 = nn.Linear(in_features = 50, out_features = 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        # Apply ReLU\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        # Apply ReLU\n",
    "        x = F.relu(x)\n",
    "        # Now flatten the input        \n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        # Apply ReLU\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "network = CNNNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_network.parameters(), lr = 1e-3, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.602\n",
      "[1,  4000] loss: 0.284\n",
      "[1,  6000] loss: 0.200\n",
      "[1,  8000] loss: 0.171\n",
      "[1, 10000] loss: 0.156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7b14b2ccbaca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m  \u001b[0;31m# variable to accumulate the loss across mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# set model to training mode for gradient accumulation (often forgotten and leads to bugs!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# loop through the mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# get the inputs; data is a list of [inputs, labels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \"\"\"\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"std evaluated to zero after conversion to {dtype}, leading to division by zero.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_cnn_model(network, train_dataloader, val_dataloader, optimizer, criterion):\n",
    "    min_val_loss = float(\"inf\")\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        network.train()\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "        network.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = network(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                # print statistics\n",
    "                val_loss += loss.item()\n",
    "                if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                    print(f'[{epoch + 1}, {i + 1:5d}] loss: {val_loss / 2000:.3f}')\n",
    "                    val_loss = 0.0\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            print(f\"The new best model is at epoch {epoch}\")\n",
    "            torch.save(network.state_dict(), PATH)\n",
    "        print(f'Epoch: {epoch} over')\n",
    "\n",
    "train_cnn_model(network=cnn_network, train_dataloader=trainloader, val_dataloader=valloader,\n",
    "                optimizer=optimizer, criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "446bff28cea4a303fa29c7e32efeecb1b4166f5c6178c2995e822330431e6a28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
